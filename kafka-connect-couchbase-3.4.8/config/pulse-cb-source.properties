# A unique string that identifies the Connect cluster group this worker belongs to.
group.id=test1-lhs-couchbase-source-group1

# Arbitrary unique name for the connector. Attempting to register
# two connectors with the same name will fail.
name=test1-lhs-rhs-connector1

# The Java class for the connector.
connector.class=com.couchbase.connect.kafka.CouchbaseSourceConnector

# The maximum number of tasks that should be created for this connector.
tasks.max=2

# Publish to this Kafka topic.
topic.name=test1-pulse-events

# Connect to this Couchbase cluster (comma-separated list of bootstrap nodes).
#connection.cluster_address=127.0.0.1
#connection.cluster_address=flink_docker_couchbase1_1_70fb2cda18f3,VIDDRLXDCUVAP02.pru.intranet.asia
connection.cluster_address=VIDDRLXDCUVAP02.pru.intranet.asia
connection.timeout.ms=2000

# Optionally connect to Couchbase Server over a secure channel.
# If the KAFKA_COUCHBASE_SSL_KEYSTORE_PASSWORD environment variable is set,
# it will override the password specified here.
#   connection.ssl.enabled=true
#   connection.ssl.keystore.location=/tmp/keystore
#   connection.ssl.keystore.password=secret

# Read from this Couchbase bucket using these credentials.
# If the KAFKA_COUCHBASE_PASSWORD environment variable is set,
# it will override the password specified here.
connection.bucket=content
connection.username=Administrator
connection.password=password

# Transform a Couchbase document change notification into a Kafka message
# using this Java class, which should extend com.couchbase.connect.kafka.handler.source.SourceHandler.
# Legacy handlers implementing com.couchbase.connect.kafka.converter.Converter will also work.
#dcp.message.converter.class=com.couchbase.connect.kafka.handler.source.DefaultSchemaSourceHandler

# To publish schemaless JSON documents exactly like the Couchbase documents, use these two lines instead:
dcp.message.converter.class=com.couchbase.connect.kafka.handler.source.RawJsonSourceHandler

# Control which Couchbase document change notifications get published to Kafka
# using this Java class, which must implement com.couchbase.connect.kafka.filter.Filter.
event.filter.class=com.couchbase.connect.kafka.filter.AllPassFilter

# apply any transformations
transforms=deserializeJson,customTransformations
transforms.deserializeJson.type=com.couchbase.connect.kafka.transform.DeserializeJson
transforms.customTransformations.type=org.apache.kafka.connect.transforms.CustomTransform$Value

# Specifies when in Couchbase history the connector should start streaming from.
# Modes starting with "SAVED_OFFSET" tell the connector to resume from when each
# vBucket's state was most recently saved by the Kafka Connect framework, falling back
# to the secondary mode if no saved state exists for a vBucket.
couchbase.stream_from=SAVED_OFFSET_OR_BEGINNING
#couchbase.stream_from=SAVED_OFFSET_OR_NOW
#couchbase.stream_from=BEGINNING
#couchbase.stream_from=NOW

# To reduce bandwidth usage, Couchbase Server 5.5 and later can send documents to the connector in compressed form.
# (Messages are always published to the Kafka topic in uncompressed form, regardless of this setting.)
# If the requested mode is not supported by your version of Couchbase Server, compression will be disabled.
#   ENABLED - (default) Couchbase Server decides whether to use compression
#             on a per-document basis, depending on whether the compressed form of the
#             document is readily available. Select this mode to prioritize Couchbase Server
#             performance and reduced bandwidth usage (recommended).
#             *Requires Couchbase Server 5.5 or later*.
#   DISABLED - No compression. Select this mode to prioritize reduced CPU load for the Kafka connector.
#   FORCED - Compression is used for every document, unless compressed size is greater than uncompressed size.
#            Select this mode to prioritize bandwidth usage reduction above all else.
#            *Requires Couchbase Server 5.5 or later*.
couchbase.compression=ENABLED
#couchbase.compression=DISABLED
#couchbase.compression=FORCED

# The amount of heap space to reserve for the flow control buffer.
couchbase.flow_control_buffer=128m

# In some failover scenarios, Couchbase Server may roll back (undo) database
# changes that have not yet been persisted across all replicas. By default,
# the Kafka connector will poll Couchbase Server and defer event publication
# until the change has been persisted to all replicas in the cluster,
# at which time the change is unlikely to be rolled back. This feature
# introduces some latency, and increases connector memory usage and network
# traffic, but prevents rolled-back changes from appearing in the Kafka topic.
#
# The longer the polling interval, the larger the flow control buffer required
# in order to maintain steady throughput.
#
# If instead you wish to publish events immediately, set the polling interval to `0`.
# If you do, be aware that when rollbacks occur you may end up with events
# in the Kafka topic from an "alternate timeline" in Couchbase Server's history.
#
# If the source is an ephemeral bucket (which never persists documents)
# this value must be set to `0` to disable the persistence check.
couchbase.persistence_polling_interval=30s
